# File: src/pipeline/main.py
# Purpose: Orchestrate data collection, preprocessing, model training, and signal generation.

from pathlib import Path
import pandas as pd
from datetime import datetime, timezone

from src.collectors.products import get_all_products
from src.collectors.fetch_candles import fetch_all_symbols
from src.config import DATA_PATH
from src.preprocess.preprocess import run_preprocessing


# =========================================================
# ğŸ§© Data Collection Stage
# =========================================================
def run_data_collection(resolution='1h', days=7) -> pd.DataFrame:
    """
    Run full data collection workflow:
      1. Fetch product metadata
      2. Fetch historical candles
      3. Return combined DataFrame
    """
    print("ğŸ“¦ Step 1: Fetching available products...")
    products_df = get_all_products()
    print(f"âœ… {len(products_df)} products fetched.")

    print("\nğŸ•“ Step 2: Fetching historical candles...")
    candle_df = fetch_all_symbols(resolution=resolution, days=days)

    if candle_df.empty:
        print("âŒ No candle data collected.")
        return pd.DataFrame()

    print(f"âœ… Collected candles for {candle_df['symbol'].nunique()} symbols.")
    return candle_df


# =========================================================
# ğŸš€ Main Pipeline
# =========================================================
def main():
    """
    Main orchestrator pipeline:
      1. Data Collection
      2. Preprocessing & Feature Engineering
      3. Model Training
      4. Signal Generation
      5. Forward-test data isolation (latest hour)
    """
    print("ğŸš€ Starting main pipeline...\n")

    # ===== STAGE 1: DATA COLLECTION =====
    candles = run_data_collection(resolution="1h", days=15)
    if candles.empty:
        print("âŒ No data fetched, aborting pipeline.")
        return

    print("\nğŸ“Š Data Collection Summary:")
    print(f"Symbols collected : {candles['symbol'].nunique()}")
    print(f"Total candles     : {len(candles)}")

    # Detect and show date range
    time_col = "timestamp" if "timestamp" in candles.columns else "time"
    if time_col in candles.columns:
        print(f"Data range: {candles[time_col].min()} â†’ {candles[time_col].max()}")
    else:
        print("âš ï¸ No timestamp column found in candle data.")

    # ===== STAGE 1.5: EXCLUDE LAST HOUR =====
    cutoff = datetime.now(timezone.utc).replace(minute=0, second=0, microsecond=0)
    print(f"\nâ³ Excluding current unfinished hour: {cutoff}")

    if "timestamp" in candles.columns:
        before_filter = len(candles)
        candles = candles[candles["timestamp"] < cutoff]
        removed = before_filter - len(candles)
        print(f"ğŸ§¹ Removed {removed} recent rows (unfinished candles).")

    # Save forward-test data (last 30 candles per symbol for indicator context)
    print("\nğŸ“¦ Creating forward-test dataset (last 30 candles per symbol)...")
    forward_test = (
        candles.groupby("symbol")
        .tail(30)  # 30 = enough lookback for RSI, EMA, Bollinger
        .reset_index(drop=True)
    )
    forward_path = DATA_PATH / "processed" / "forward_test.parquet"
    forward_test.to_parquet(forward_path, index=False)
    print(f"ğŸ’¾ Forward-test data saved â†’ {forward_path} (shape={forward_test.shape})")

    # Save filtered candles
    processed_path = DATA_PATH / "processed" / "filtered_candles.parquet"
    candles.to_parquet(processed_path, index=False)
    print(f"ğŸ’¾ Filtered candles saved â†’ {processed_path}")

    # ===== STAGE 2: PREPROCESSING =====
    print("\nğŸ§¹ Stage 2: Preprocessing & Feature Engineering...")
    features = run_preprocessing()
    if features is not None and not features.empty:
        print(f"âœ… Feature dataset created. Shape: {features.shape}")
    else:
        print("âš ï¸ Feature generation failed or returned empty DataFrame.")

    # ===== STAGE 3: MODEL TRAINING =====
    print("\nğŸ‹ï¸ Stage 3: Training Model...")
    from src.models.trainer import train_model
    train_model()

    # ===== STAGE 4: SIGNAL GENERATION =====
    print("\nğŸ“ˆ Stage 4: Generating Numeric Trade Signals...")
    from src.decision.signals import generate_signals
    generate_signals()

    signals_path = DATA_PATH / "processed" / "signals.csv"
    print(f"ğŸ’¾ Signals saved â†’ {signals_path}")

    print("\nâœ… Pipeline completed successfully.")


# =========================================================
# ğŸ Entry Point
# =========================================================
if __name__ == "__main__":
    main()
